{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_CatDogs.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1WvnA5SLqN_xh9eUhxL7QPPMrqamajaff",
      "authorship_tag": "ABX9TyNiUf0CzE/b9M5vZizBE8Kq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jairajpal/DeepLearning/blob/master/CNN_CatDogs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eM403OTqehaS",
        "outputId": "cc7ac173-94d2-49fd-d328-7fa99f6b18ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from zipfile import ZipFile\n",
        "file_name=\"/content/drive/My Drive/dataset.zip\"\n",
        "with ZipFile(file_name,'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('finish')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "finish\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sasU-wYfeAY"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Conv2D\n",
        "import pandas as pd"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TytMyiqzfsnm"
      },
      "source": [
        "CNN_Classifier=Sequential()\n",
        "#convolution\n",
        "CNN_Classifier.add(Conv2D(32,3,3,input_shape=(64,64,3),activation='relu'))\n",
        "#poopling\n",
        "CNN_Classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
        "#convolution\n",
        "CNN_Classifier.add(Conv2D(32,3,3,activation='relu'))\n",
        "#poopling\n",
        "CNN_Classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
        "#flattening\n",
        "CNN_Classifier.add(Flatten())\n",
        "#connection\n",
        "CNN_Classifier.add(Dense(units=128,activation='relu'))\n",
        "CNN_Classifier.add(Dense(units=1,activation='sigmoid'))\n",
        "#compile the CNN\n",
        "CNN_Classifier.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5y8jttuh5g-",
        "outputId": "e440e94e-1473-41f6-dbf6-c103a0dd5e9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "training_set = train_datagen.flow_from_directory(\n",
        "        '/content/dataset/training_set',\n",
        "        target_size=(64, 64),\n",
        "        batch_size=32,\n",
        "        class_mode='binary')\n",
        "test_set = test_datagen.flow_from_directory(\n",
        "        '/content/dataset/test_set',\n",
        "        target_size=(64, 64),\n",
        "        batch_size=32,\n",
        "        class_mode='binary')\n",
        "CNN_Classifier.fit(\n",
        "        training_set,\n",
        "        steps_per_epoch=100,\n",
        "        epochs=10,\n",
        "        validation_data=test_set,\n",
        "        validation_steps=2000)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 8000 images belonging to 2 classes.\n",
            "Found 2000 images belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.6804 - accuracy: 0.5731WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2000 batches). You may need to use the repeat() function when building your dataset.\n",
            "100/100 [==============================] - 18s 179ms/step - loss: 0.6804 - accuracy: 0.5731 - val_loss: 0.6704 - val_accuracy: 0.5780\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 12s 123ms/step - loss: 0.6693 - accuracy: 0.5928\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 12s 124ms/step - loss: 0.6571 - accuracy: 0.6125\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 12s 124ms/step - loss: 0.6594 - accuracy: 0.6034\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 12s 124ms/step - loss: 0.6476 - accuracy: 0.6359\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 12s 125ms/step - loss: 0.6420 - accuracy: 0.6409\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 12s 124ms/step - loss: 0.6404 - accuracy: 0.6316\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 13s 125ms/step - loss: 0.6420 - accuracy: 0.6278\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 12s 125ms/step - loss: 0.6311 - accuracy: 0.6416\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 13s 125ms/step - loss: 0.6301 - accuracy: 0.6356\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa561a6ce80>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2PPFAkDkRa1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}